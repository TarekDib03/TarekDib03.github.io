MITx: 15.071x The Analytics Edge - The Steven's Supreme Court Decision
========================================================
# Classification and Regression Tree (CART)
### Tarek Dib
### April 6, 2014

### *Itroduction*
The data are cases from 1994 through 2001. In this period, same nine justices presided Supreme Court of the United States (SCOTUS). They are: Breyer, Ginsburg, Kennedy, O’Connor, Rehnquist (Chief Justice), Scalia, Souter, Stevens, Thomas. This is the longest period of time with the same set of justices in over 180 years. We will focus on predicting Justice Stevens’ decisions, who started out moderate, but became more liberal, self-proclaimmed conservative. 

Note: CART model is a series of decision rules.

### *Variables*
    Dependent Variable: Did Justice Stevens vote to reverse the lower court decision? 1 = reverse, 0 = affirm
    Independent Variables: Properties of the case
    Circuit court of origin (1st – 11th, DC, FED)
    Issue area of case (e.g., civil rights, federal taxation)
    Type of petitioner, type of respondent (e.g., US, an employer)
    Ideological direction of lower court decision (conservative or liberal)
    Whether petitioner argued that a law/practice was unconstitutional
    
    More information about US Court of Appeals can be found in the following link:
    http://en.wikipedia.org/wiki/United_States_courts_of_appeals

### *Building the CART Model* 
```{r}
# Read in the data
setwd("Analytics/Weeks/Week4/Codes")
stevens = read.csv("stevens.csv")
str(stevens)     # Docket is a unique identifier for each case!

# Split the data
library(caTools)
set.seed(3000)
split = sample.split(stevens$Reverse, SplitRatio = 0.7)
Train = subset(stevens, split==TRUE)
Test = subset(stevens, split==FALSE)

# Install rpart library
install.packages("rpart")
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)

# CART model
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, 
                    method="class", data = Train, control=rpart.control(minbucket=25))

# Make predictions
PredictCART = predict(StevensTree, newdata = Test, type = "class")
tCART <- table(Test$Reverse, PredictCART)
# Accuracy of the model
(tCART[1,1]+tCART[2,2])/sum(tCART)
# Load the ROCR library
library(ROCR)
# Performance of the model
PredictROC = predict(StevensTree, newdata = Test)
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr", "fpr")  #tpr: true positive rate. 

# Compute the AUC
as.numeric(performance(pred, "auc")@y.values)
```

```{r fig.width=14, fig.height=6}
# Splits
prp(StevensTree)
```

```{r fig.width=8, fig.height=6}
# ROC curve
plot(perf)
```

### *Random Forests*
This method is similar to the CART method. However, it improves the prediction accuracy of CART and works by building a large number of CART trees! Less interpretable than the CART method.
```{r}
# Install randomForest package
install.packages("randomForest")
library(randomForest)

# Build random forest model
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )

set.seed(200)
# Convert outcome to factor
Train$Reverse = as.factor(Train$Reverse)
Test$Reverse = as.factor(Test$Reverse)

# Try again
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )

# Make predictions
PredictForest = predict(StevensForest, newdata = Test)
tRF = table(Test$Reverse, PredictForest)
(tRF[1,1]+tRF[2,2])/sum(tRF)
```

### *K-fold Cross Validation*
A method to properly select the minibucket parameter in the CART method!
#### *Procedure*
    Giving training set, split into k folds (e.g. k=5)
    Use k-1 folds to estimate a model, and test model on the remaining fold ("Validation set") for each candidate paremeter value. Example select folds 1,2,3,4 and then validate (predict) fold 5. Repeat by selecting folds 1,2,3,5 and validate on fold 4. And so forth. i.e. repeat this for each of the k folds.
    Then for each candidate paremeter and for each fold, compute the accuracy of the model. THen average the accuracy over the k folds.
    
```{r}
# Install cross-validation packages
install.packages("caret")
library(caret)
install.packages("e1071")
library(e1071)

# Define cross-validation experiment
fitControl = trainControl( method = "cv", number = 10 )
cartGrid = expand.grid( .cp = (1:50)*0.01) 

# Perform the cross validation. This is to compute cp.
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method = "rpart", trControl = fitControl, tuneGrid = cartGrid )

# Create a new CART model
StevensTreeCV = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, method="class", data = Train, control=rpart.control(cp = 0.2))

# Make predictions
PredictCV <- predict(StevensTreeCV, newdata = Test, type = "class")
tCV <- table(Test$Reverse, PredictCV)
(tCV[1,1] + tCV[2,2])/sum(tCV)
```