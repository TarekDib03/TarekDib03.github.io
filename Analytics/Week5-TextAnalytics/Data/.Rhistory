strwrap(wiki[1])
strwrap(wiki$Added[1])
corpusAdded <- Corpus(VectorSource(wiki$Added))
strwrap(corpusAdded[1])
corpusAdded <- tm_map(corpusAdded, removeWords, stopwords("english"))
corpusAdded <- tm_map(corpusAdded, stemDocument)
corpusAdded[1]
corpusAdded
corpusAdded[[1]]
dtm = DocumentTermMatrix(corpusAdded)
dtm
1-0.3/100
dtmAdded = removeSparseTerms(dtm, 0.997)
dtmAdded
sparseAdded = removeSparseTerms(dtm, 0.997)
wordsAdded <- as.data.frame(as.matrix(sparseAdded))
head(wordsAdded)
colnames(wordsAdded) = paste("A", colnames(wordsAdded))
names(wordsAdded)
corpusRemoved <- Corpus(VectorSource(wordsAdded))
corpusRemoved[[1]]
wordsAdded
colnames(wordsAdded)
names(wiki)
corpusRemoved <- Corpus(VectorSource(wiki$Removed))
corpusRemoved[[1]]
corpusRemoved
corpusRemoved[[1]]
corpusRemoved[[2]]
corpusRemoved <- tm_map(corpusRemoved, removeWords, stopwords("english"))
corpusRemoved <- tm_map(corpusRemoved, stemDocument)
dtmRemoved = DocumentTermMatrix(corpusRemoved)
dtmRemoved
sparseRemoved = removeSparseTerms(dtmRemoved, 0.997)
sparseRemoved
wordsRemoved <- as.data.frame(as.matrix(sparseRemoved))
colnames(wordsRemoved) <- paste("R", colnames(wordsRemoved))
colnames(wordsRemoved)
wikiWords = cbind(wordsAdded, wordsRemoved)
colnames(wikiWords)
wikiWords$Vandal <- wiki$Vandal
set.seed(123)
spl <- sample.split(wikiWords$Vandal, 0.7)
train <- subset(wikiWords, spl == T)
test <- subset(wikiWords, spl == F)
table(test$Vandal)
table(test$Vandal)[1] / sum(table(test$Vandal))
library(rpart)
library(rpart.plot)
wikiCART <- rpart(Vandal ~. data=train, method="class")
wikiCART <- rpart(Vandal ~., data=train, method="class")
pred = predict(wikiCART, newdata=test, type="class")
pred
pred[1:10,]
pred = predict(wikiCART, newdata=test)
pred[1:10,]
pred = predict(wikiCART, newdata=test, type="class")
table(wikiWords$Vandal, pred > 0.5)
table(wikiWords$Vandal, pred)
table(test$Vandal, pred > 0.5)
table(test$Vandal, pred >= 0.5)
table(test$Vandal, pred)
(t1[1,1] + t1[2,2])/(sum(t1))
t1 <- table(test$Vandal, pred)
(t1[1,1] + t1[2,2])/(sum(t1))
prp(wikiCART0)
prp(wikiCART)
wikiWords2 <- wikiWords
wikiWords2$HTTP = ifelse(grepl("http",wiki$Added,fixed=TRUE), 1, 0)
sum(wikiWords$HTTP)
sum(wikiWords2$HTTP)
wikiTrain2 = subset(wikiWords2, spl==TRUE)
wikiTest2 = subset(wikiWords2, spl==FALSE)
wikiCART2 <- rpart(Vandal ~ ., data=wikiTrain2, method="class")
pred2 <- predict(wikiCART2, newdata=wikiTest2, type="class")
t2 <- table(wikiTest2$Vandal, pred2)
t2
(t2[1,1]+t2[2,2])/sum(t2)
wikiWords2$NumWordsAdded = rowSums(as.matrix(dtmAdded))
wikiWords2$NumWordsRemoved = rowSums(as.matrix(dtmRemoved))
mean(wikiWords2$NumWordsAdded)
head(wikiWords2$NumWordsAdded)
sum(wikiWords2$NumWordsAdded)
length(wikiWords2$NumWordsAdded)
length(wikiWords$Added)
length(WordsAdded)
length(wordsAdded)
sum(wikiWords2$NumWordsAdded)/166
max(wikiWords2$NumWordsAdded)
mean(wikiWords2$NumWordsAdded)
dtmAdded
sum(wikiWords2$NumWordsAdded)
3876/2840
length(wikiWords2$NumWordsAdded)
mean(wikiWords2$NumWordsAdded)
wikiTrain3 = subset(wikiWords2, spl==TRUE)
wikiTest3 = subset(wikiWords2, spl==FALSE)
wikiCART3 <- rpart(Vandal ~ ., data=wikiTrain3, method="class")
pred3 <- predict(wikiCART3, newdata=wikiTest3, type="class")
t3 <- table(wikiTest3$Vandal, pred3)
(t3[1,1]+t3[2,2])/sum(t3)
corpusAdded <- Corpus(VectorSource(wiki$Added))
# Remove Stop words
corpusAdded <- tm_map(corpusAdded, removeWords, stopwords("english"))
corpusAdded <- tm_map(corpusAdded, stemDocument)
# Look at the first document
corpusAdded[[1]]
# Create matrix
dtmAdded = DocumentTermMatrix(corpusAdded)
dtmAdded
corpusRemoved <- Corpus(VectorSource(wiki$Removed))
corpusRemoved <- tm_map(corpusRemoved, removeWords, stopwords("english"))
corpusRemoved <- tm_map(corpusRemoved, stemDocument)
dtmRemoved = DocumentTermMatrix(corpusRemoved)
dtmRemoved
wikiWords2$NumWordsAdded = rowSums(as.matrix(dtmAdded))
wikiWords2$NumWordsRemoved = rowSums(as.matrix(dtmRemoved))
mean(wikiWords2$NumWordsAdded)
wikiTrain3 = subset(wikiWords2, spl==TRUE)
wikiTest3 = subset(wikiWords2, spl==FALSE)
wikiCART3 <- rpart(Vandal ~ ., data=wikiTrain3, method="class")
pred3 <- predict(wikiCART3, newdata=wikiTest3, type="class")
t3 <- table(wikiTest3$Vandal, pred3)
(t3[1,1]+t3[2,2])/sum(t3)
names(wiki)
wikiWords3 = wikiWords2
wikiWords3$Minor = wiki$Minor
wikiWords3$Loggedin = wiki$Loggedin
wikiWords3$Minor = wiki$Minor
wikiWords3$Loggedin = wiki$Loggedin
# Build a CART model
wikiTrain4 = subset(wikiWords3, spl==TRUE)
wikiTest4 = subset(wikiWords3, spl==FALSE)
wikiCART4 <- rpart(Vandal ~ ., data=wikiTrain4, method="class")
pred4 <- predict(wikiCART4, newdata=wikiTest4, type="class")
t4 <- table(wikiTest4$Vandal, pred4)
(t4[1,1]+t4[2,2])/sum(t4)
prp(wikiCART4)
trials <- read.csv("clinical_trial.csv", stringsAsFactors = F)
str(trials)
max(nchar(trials$abstract))
nchar(trials$abstract)
max(nchar(trials$abstract))
sum(trials$abstract == 0)
sum(nchar(trials$abstract) == 0)
trials$article[1]
names(trials)
trials$title[1]
nchar(trials$title[1])
min(nchar(trials$title))
min(nchar(trials$title)) - nchar("")
nchar("")
min(nchar(trials$title))
which.min(nchar(trials$title))
trials$title[which.min(nchar(trials$title))]
names(trials)
library(tm)
corpusTitle <- Corpus(VectorSource(trials$title))
corpusAbstract <- Corpus(VectorSource(trials$abstract))
corpusTitle <- tm_map(corpusTitle, tolower)
corpusAbstract <- tm_map(corpusAbstract, tolower)
corpusAbstract <- tm_map(corpusAbstract, removePunctuation)
corpusTitle <- tm_map(corpusTitle, removePunctuation)
corpusTitle <- tm_map(corpusTitle, removeWords, stopwords("english"))
corpusAbstract <- tm_map(corpusAbstract, removeWords, stopwords("english"))
corpusTitle <- tm_map(corpusTitle, stemDocument)
corpusAbstract <- tm_map(corpusAbstract, stemDocument)
corpusTitle[[1]]
dtmTitle = DocumentTermMatrix(corpusTitle)
dtmAbstract = DocumentTermMatrix(corpusAbstract)
dtmTitle
dtmAbstract
sparseTitle <- removeSparseTerms(dtmTitle, 0.95)
sparseAbstract <- removeSparseTerms(dtmAbstract, 0.95)
sparseTitle
sparseAbstract
dtmTitle <- removeSparseTerms(dtmTitle, 0.95)
dtmAbstract <- removeSparseTerms(dtmAbstract, 0.95)
dtmTitle <- as.data.frame(as.matrix(dtmTile))
dtmTitle <- as.data.frame(as.matrix(dtmTitle))
dtmTitle <- as.data.frame(as.matrix(dtmTitle))
dtmAbstract <- as.data.frame(as.matrix(dtmAbstract))
dtmTitle
dtmTitle <- DocumentTermMatrix(corpusTitle)
dtmAbstract <- DocumentTermMatrix(corpusAbstract)
dtmTitle <- removeSparseTerms(dtmTitle, 0.95)
dtmAbstract <- removeSparseTerms(dtmAbstract, 0.95)
dtmTitle
dtmAbstract
dtmTitle[[1]]
dtmTitle
dtmAbstract
corpusAbstract[[1]]
corpusAbstract[[2]]
colSums(corpusAbstract)
colSums(as.matrix(corpusAbstract))
colSums(as.matrix(dtmAbstract))
max(colSums(as.matrix(dtmAbstract)))
dtmAbstract[which.max(colSums(as.matrix(dtmAbstract)))]
dtmAbstract[8381]
dtmAbstract == max(colSums(as.matrix(dtmAbstract)))
?sort
sort(colSums(as.matrix(dtmAbstract)))
cs == colSums(dtmAbstract)
cs <- colSums(dtmAbstract)
dtmTitle <- as.data.frame(as.matrix(dtmTitle))
dtmAbstract <- as.data.frame(as.matrix(dtmAbstract))
cs <- colSums(dtmAbstract)
which.max(cs)
colnames(dtmTitle) = paste0("T", colnames(dtmTitle))
colnames(dtmAbstract) = paste0("A", colnames(dtmAbstract))
dtmTile
dtmTitle
nrows(dtmTitle)
nrow(dtmTitle)
colnames(dtmAbstract) = paste0("A", colnames(dtmAbstract))
colnames(dtmAbstract)
colnames(dtmTitle)
dtm <- cbind(dtmTile, dtmAbstract)
dtm <- cbind(dtmTitle, dtmAbstract)
ncol(dtm)
names(trials)
dtm$trial <- trials$trial
ncol(dtm)
library(caTools)
set.seed(144)
spl <- sample.split(dtm$trial, 0.7)
train <- subset(trials, spl == T)
test <- subset(trials, spl == F)
table(train$trial)
table(train$trial)[1] / sum(table(train$trial))
library(rpart)
library(rpart.plot)
trialsCART <- rpart(trial ~., data=train, method="class")
prp(trialsCART)
names(trials)
library(rpart.plot)
prp(trialsCART)
prp(wikiCART)
trialsCART <- rpart(trial~., data=train, method="class")
colnames(dtm)
dtmTitle <- as.data.frame(as.matrix(dtmTitle))
dtmAbstract <- as.data.frame(as.matrix(dtmAbstract))
colnames(dtmTitle)
colnames(dtmAbstract)
getwd()
plot(trialsCART)
train
head(train,3)
dtm <- cbind(dtmTitle, dtmAbstract)
colnames(dtm)
library(caTools)
set.seed(144)
spl <- sample.split(dtm$trial, 0.7)
spl <- sample.split(dtm$trial, SplitRatio = 0.7)
?sample.split
spl <- sample.split(dtm$trial, SplitRatio = 0.7)
train <- subset(trials, spl == T)
head(dtm)
library(caTools)
set.seed(144)
spl <- sample.split(dtm, SplitRatio = 0.7)
train <- subset(trials, spl == T)
test <- subset(trials, spl == F)
trialsCART <- rpart(trial~., data=train, method="class")
prp(trialsCART)
trials$trial
levels(trials$trial)
table(trials$trial)
table(dtm$trial)
dtm <- cbind(dtmTitle, dtmAbstract)
table(dtm$trial)
dtm
colnames(dtm)
dtm
dtm$trial
dtmTitle <- removeSparseTerms(dtmTitle, 0.95)
trials <- read.csv("clinical_trial.csv", stringsAsFactors = F)
max(nchar(trials$abstract))
sum(nchar(trials$abstract) == 0)
trials$title[which.min(nchar(trials$title))]
corpusTitle <- Corpus(VectorSource(trials$title))
corpusAbstract <- Corpus(VectorSource(trials$abstract))
# Convert to lower case
corpusTitle <- tm_map(corpusTitle, tolower)
corpusAbstract <- tm_map(corpusAbstract, tolower)
# Remove punctuation
corpusTitle <- tm_map(corpusTitle, removePunctuation)
corpusAbstract <- tm_map(corpusAbstract, removePunctuation)
# Remove Stop words
corpusTitle <- tm_map(corpusTitle, removeWords, stopwords("english"))
corpusAbstract <- tm_map(corpusAbstract, removeWords, stopwords("english"))
# Stem the words
corpusTitle <- tm_map(corpusTitle, stemDocument)
corpusAbstract <- tm_map(corpusAbstract, stemDocument)
# Look at the first document
corpusTitle[[1]]
# Create matrix
dtmTitle <- DocumentTermMatrix(corpusTitle)
dtmAbstract <- DocumentTermMatrix(corpusAbstract)
dtmTitle
dtmAbstract
# Filter out sparse terms by keeping only terms that appear in at least 5% or more of the documents
dtmTitle <- removeSparseTerms(dtmTitle, 0.95)
dtmAbstract <- removeSparseTerms(dtmAbstract, 0.95)
dtmTitle
dtmAbstract
# Convert dtmTitle and dtmAbstract to data frames
titleDf <- as.data.frame(as.matrix(dtmTitle))
abstractDf <- as.data.frame(as.matrix(dtmAbstract))
colnames(titleDf) <- paste0("T", colnames(titleDf))
colnames(abstractDf) <- paste0("A", colnames(abstractDf))
colnames(titleDf)
colnames(abstractDf)
dtm <- cbind(titleDf, abstractDf)
names(dtm)
dtm$trial <- trials$trial
library(caTools)
set.seed(144)
spl <- sample.split(dtm, SplitRatio = 0.7)
train <- subset(trials, spl == T)
test <- subset(trials, spl == F)
table(train$trial)[1] / sum(table(train$trial))
library(rpart)
library(rpart.plot)
trialsCART <- rpart(trial~., data=train, method="class")
prp(trialsCART)
dtm <- cbind(titleDf, abstractDf)
dtm <- cbind(dtm, trials$trial)
names(dtm)
dtm <- cbind(titleDf, abstractDf)
names(dtm)
cbind(dtm, trials$trial)
trialsCART <- rpart(trials$trial~., data=train, method="class")
spl <- sample.split(dtm, SplitRatio = 0.7)
train <- subset(trials, spl == T)
dtm <- cbind(titleDf, abstractDf)
dtm$trial <- trials$trial
library(caTools)
set.seed(144)
spl <- sample.split(dtm$trial, SplitRatio = 0.7)
train <- subset(dtm, spl == T)
test <- subset(dtm, spl == F)
colnames(abstractDf) <- paste0("A", colnames(abstractDf))
table(train$trial)[1] / sum(table(train$trial))
trialsCART <- rpart(trial~., data=train, method="class")
prp(trialsCART)
pred = predict(trialsCART)
max(pred)
pred[1:10,]
pred.prop <- pred[,2]
max(pred.prop)
pred.prob <- pred[,2]
max(pred.prob)
pred2 <- predict(trialsCART, newdata=test)
max(pred2[,2])
t1 <- table(train$trial, pred >= 0.5)
length(pred)
length(trail$trial)
length(train$trial)
t1 <- table(train$trial, pred >= 0.5, type="class")
pred <- predict(trialsCART, type="class")
t1 <- table(train$trial, pred)
pred
(t1[1,1] + t1[2,2])/(sum(t1))
t1
441/(441+131)
631/(631+99)
t1[2,2]/(t1[2,2] + t1[2,1])
t1[1,1]/(t1[1,1] + t1[1,2])
predTest <- predict(trialsCART, newdata = test, type="class")
t2 <- table(test$trial, predTest)
t2
(t2[1,1] + t2[2,2])/(sum(t2))
library(ROCR)
predROCR = prediction(predTest, test$trial)
predTest <- predict(trialsCART, newdata = test) # type="class" means the threshold is 0.5
t2 <- table(test$trial, predTest)
predROCR = prediction(predTest, test$trial)
predROCR = prediction(predTest[,2], test$trial)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values
predTest <- predict(trialsCART, newdata = test)[,2]
t2 <- table(test$trial, predTest >= 0.5)
(t2[1,1] + t2[2,2])/(sum(t2))
plot(perfROCR, colorize=TRUE)
predTrain <- predict(trialsCART, type="class")[,2]
predTrain <- predict(trialsCART)[,2]
t1 <- table(train$trial, predTrain >= 0.5)
(t1[1,1] + t1[2,2])/(sum(t1))
emails <- read.csv("emails.csv", stringsAsFactors = F)
str(emails)
sum(emails$spam == 1)
strwrap(emails$text[1:2])
max(nchar(emails$text))
which.min(nchar(emails$text))
library(tm)
corpus <- Corpus(VectorSource(emails$text))
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
dtm <- DocumentTermMatrix(corpus)
dtm
spdtm <- removeSparseTerms(dtm, 0.95)
spdtm
emailsSparse <- as.data.frame(as.matrix(spdtm))
emailsSparse <- as.data.frame(as.matrix(spdtm), make.names=T)
names(emailsSparse)
sort(colSums(emailsSparse))
which.max(colSums(emailsSparse))
emailsSparse$spam <- emails$spam
a = emailsSparse[emailsSparse$spam==0,]
colSums(a)
colSums(a) > 5000
sum(colSums(a) > 5000)
sum(colSums(ham) > 5000)
ham <- emailsSparse[emails$Sparse==0,]
sum(colSums(ham) > 5000)
ham <- emailsSparse[emailsSparse$spam==0,]
sum(colSums(ham) > 5000)
Spam <- emailsSparse[emailsSparse$spam==1,]
sum(colSums(ham) >= 1000)
sum(colSums(ham) > 1000)
sort(colSums(subset(emailsSparse, spam == 1)))
library(caTools)
set.seed(123)
spl <- sample.split(spdtm$spam, SplitRatio = 0.7)
spl <- sample.split(spdtm, SplitRatio = 0.7)
train <- subset(spdtm, spl == T)
test <- subset(spdtm, spl == F)
spamLog <- glm(spam~., data = train, family=binomial)
emailsSparse$spam <- as.factor(emailsSparse$spam)
spl <- sample.split(emailsSparse$spam, SplitRatio = 0.7)
train <- subset(emailsSparse, spl == T)
test <- subset(emailsSparse, spl == F)
spamLog <- glm(spam~., data = train, family=binomial)
predLog <- predict(spamLog, type="response")
sum(predLog < 0.00001)
length(predLog)
sum(predLog > 0.99999)
sum(predLog > 0.00001 & predLog < 0.99999)
summary(spamLog)
library(rpart)
library(rpart.plot)
spamCART <- rpart(spam~., data=train, method="class")
prp(spanCART)
prp(spamCART)
tLog <- table(emailsSparse$spam, predLog)
tLog <- table(emailsSparse$spam, predLog >= 0.5)
length(predLog)
length(emailsSparse$spam)
tLog <- table(train$spam, predLog >= 0.5)
(tLog[1,1] + tLog[2,2]) / sum(tLog)
predLog
library(ROCR)
predROCR = prediction(predLog, train$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize=TRUE)
performance(predROCR, "auc")@y.values
prp(spamCART)
predTrain <- predict(spamCART)[,2]
tCART <- table(train$spam, predTrain >= 0.5)
(t1[1,1] + t1[2,2])/(sum(t1))
(tCART[1,1] + tCART[2,2])/(sum(tCART))
predROCRCART = prediction(predTrain, train$spam)
perfROCRCART = performance(predROCRCART, "tpr", "fpr")
performance(predROCRCART, "auc")@y.values
library(randomForest)
set.seed(123)
spamRF <- randomForest(spam~., data=train)
spamRF <- randomForest(spam~., data=train, method="class")
names(train)
library(randomForest)
set.seed(123)
spamRF <- randomForest(spam~ ., data=train)
spamRF <- randomForest(spam~., data=train)
spamRF <- randomForest(spam~. -000, data=train)
spamRF <- randomForest(spam~. -'000', data=train)
spamRF <- randomForest(spam~. -train[1], data=train)
spamRF <- randomForest(spam~.-train[1], data=train)
train[1]
names(train)
train$000
train$'000'
spamRF <- randomForest(spam~.-'000', data=train)
predTestLog <- predict(spamLog, newdata = test, type="response")
t2 <- table(test$spam, predTest >= 0.5)
t2 <- table(test$spam, predTestLog >= 0.5)
(t2[1,1] + t2[2,2])/(sum(t2))
predROCRLog = prediction(predTestLog, test$spam)
performance(predROCRLog, "auc")@y.values
t3 <- table(test$spam, predTestCART >= 0.5)
predTestCART <- predict(spamCART, newdata = test)[,2]
t3 <- table(test$spam, predTestCART >= 0.5)
(t3[1,1] + t3[2,2])/(sum(t3))
predROCRCART = prediction(predTestCART, test$spam)
performance(predROCRCART, "auc")@y.values
wordCount = rowSums(as.matrix(dtm))
install.packages("slam")
install.packages("slam")
library(slam)
wordCount = rollup(dtm, 2, FUN=sum)$v
hist(wordCount)
hist(log(wordCount))
emailsSparse$logWordCount <- log(wordCount)
boxplot(emailsSparse$logWordCount ~ emailsSparse$spam)
train2 <- subset(emailsSparse, spl==T)
test2 <- subset(emailsSparse, spl==F)
spam2CART <- rpart(spam~., data=train2, method="class")
spam2RF <- randomForest(spam~., data=train2)
spam2RF <- randomForest(spam~., data=train2, method="class")
